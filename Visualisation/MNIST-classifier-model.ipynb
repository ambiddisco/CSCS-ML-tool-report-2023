{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST classifier notebook\n",
    "This is a notebook for a brief exploration and explanation of the data and models. This model code is used for all the visualisations. These models are MNIST classifier models, the \"hello world\" of machnie learning models.\n",
    "\n",
    "The MNIST classifier dataset contains low resolution 28x28 pixel images of handwrittendigits, and the aim of the model is to recognise which digits are represented in the image, usually using a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/site-packages (3.7.1)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/site-packages (2.12.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/site-packages (from matplotlib) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from matplotlib) (22.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/abiddisco/Library/Python/3.11/lib/python/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.11/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/site-packages (from tensorflow) (0.4.12)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/site-packages (from tensorflow) (16.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/site-packages (from tensorflow) (4.23.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/site-packages (from tensorflow) (67.6.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/abiddisco/Library/Python/3.11/lib/python/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/site-packages (from tensorflow) (4.6.3)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/site-packages (from tensorflow) (1.54.2)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.11/site-packages (from tensorflow) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.11/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.11/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/site-packages (from tensorflow) (0.32.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.11/site-packages (from jax>=0.3.15->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.11/site-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.20.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in /usr/local/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Requirements:\n",
    "%pip install matplotlib tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-06 16:24:43.436577: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import random    \n",
    "import matplotlib.pyplot as plt   \n",
    "%matplotlib inline  \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, for simplicity I am using TensorFlow's keras library to create the model. This way the keras MNIST classifier dataset can be imported directly, without need to load local files, making it easy to reproduce by anyone else with TensorFlow.\n",
    "\n",
    "Once imported the requirements, we can start by preparing the dataset. First of all, it needs to be separated into a training and a testing set. There are 70'000 total datapoints, and they are by default divided into 60'000 training and 10'000 testing datapoints for most basic MNIST classifier models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has length 70000, divided into 60000 training and 10000 testing datapoints.\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# To see how the dataset was split:\n",
    "print(\"The dataset has length {}, divided into {} training and {} testing datapoints.\".format(len(X_train)+len(X_test), len(X_train), len(X_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at one of the images in the dataset, selected at random from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image corresponds to the digit 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_index = int(random.uniform(0, 60000))\n",
    "plt.matshow(X_train[random_index])\n",
    "print(\"This image corresponds to the digit\", y_train[random_index])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know what the datapoints look like, and we know that our inputs X correspond to low quality images, composed of 28x28 pixels, each with a value between 0 and 255. We want to be able to train a model to recognise these inputs are the digit they are supposed to represent, our y. Let's start by dividing the inputs by 255 so that they contain values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_divided = X_train / 255\n",
    "X_test_divided = X_test / 255"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create the model. Here is a 3 layer one, we can argue that there's actually only 2 layers because the first one is just for flattening and is an input layer, but that is still an important step. The second and third are 'dense' layers, as in fully connected. The respective sizes are 784 (= 28 * 28) for the input layer, 128 for the first dense layer, and 10 for the last, which also tranlsates to the output of 10 possible digits (0 through 9). In the dense layers we also define the activation type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    keras.layers.Dense(128, 'relu'),\n",
    "    keras.layers.Dense(10, 'sigmoid')\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compile the model, this part helps the model train itself based on the criteria given, in this case for example we want to evaluate the model based on its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2570 - accuracy: 0.9270\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1139 - accuracy: 0.9661\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0782 - accuracy: 0.9761\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0589 - accuracy: 0.9820\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0455 - accuracy: 0.9859\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0371 - accuracy: 0.9881\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0285 - accuracy: 0.9914\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0244 - accuracy: 0.9925\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0180 - accuracy: 0.9945\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0170 - accuracy: 0.9947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14ae44c50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_divided, y_train, epochs = 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, it's time to evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 864us/step - loss: 0.0772 - accuracy: 0.9778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07721719145774841, 0.9778000116348267]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_divided, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also have saved the model metrics so as to log them, by fitting the model in a history variable, and saving the evaluation in a score variable, as in \"history = model.fit(X_train_divided, y_train, epochs = 10)\" and \"score = model.evaluate(X_test_divided, y_test)\". In any case, this specific model reaches an evaluated accuracy of almost 98%, which means it's probably overfitting.\n",
    "\n",
    "Now we have created a model, we can make some with different hyperparameters, changing anything from the number of nodes in the creation step to the evaluation metrics in the compiler. To make it easy I chose three node sizes and activation types for each of the two dense layers, and assigned them with no particular order, to try to create models with varying accuracy, whilst keeping the same compilation for simplicity's sake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2750 - accuracy: 0.9215\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1247 - accuracy: 0.9631\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0873 - accuracy: 0.9738\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0664 - accuracy: 0.9797\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0519 - accuracy: 0.9842\n",
      "313/313 [==============================] - 0s 820us/step - loss: 0.0884 - accuracy: 0.9734\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 984us/step - loss: 0.5197 - accuracy: 0.8795\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 973us/step - loss: 0.2330 - accuracy: 0.9343\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 974us/step - loss: 0.1816 - accuracy: 0.9488\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 975us/step - loss: 0.1507 - accuracy: 0.9577\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1297 - accuracy: 0.9637\n",
      "313/313 [==============================] - 0s 795us/step - loss: 0.1337 - accuracy: 0.9619\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 3.2516 - accuracy: 0.1008\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 3.2188 - accuracy: 0.0988\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 3.2209 - accuracy: 0.0988\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 3.2203 - accuracy: 0.0987\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 3.2189 - accuracy: 0.0987\n",
      "313/313 [==============================] - 0s 838us/step - loss: 3.2189 - accuracy: 0.0980\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 3.1345 - accuracy: 0.1385\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 3.1301 - accuracy: 0.1269\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 3.1393 - accuracy: 0.1235\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 3.1666 - accuracy: 0.1150\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 3.0614 - accuracy: 0.1489\n",
      "313/313 [==============================] - 0s 798us/step - loss: 3.0451 - accuracy: 0.1529\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4299 - accuracy: 0.8911\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2026 - accuracy: 0.9423\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1515 - accuracy: 0.9571\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1207 - accuracy: 0.9654\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0993 - accuracy: 0.9712\n",
      "313/313 [==============================] - 0s 827us/step - loss: 0.1050 - accuracy: 0.9693\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 1.2994 - accuracy: 0.6863\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 999us/step - loss: 0.7147 - accuracy: 0.7489\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 1000us/step - loss: 0.5650 - accuracy: 0.8230\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4699 - accuracy: 0.8724\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4080 - accuracy: 0.8920\n",
      "313/313 [==============================] - 0s 808us/step - loss: 0.3891 - accuracy: 0.8918\n"
     ]
    }
   ],
   "source": [
    "first_layer_nodes = [100, 50, 100, 50, 100, 50]\n",
    "first_layer_activation = [\"relu\", \"sigmoid\", \"softmax\", \"relu\", \"sigmoid\", \"softmax\"]\n",
    "second_layer_nodes = [10, 15, 25, 25, 15, 10]\n",
    "second_layer_activation = [\"sigmoid\", \"softmax\", \"relu\", \"relu\", \"sigmoid\", \"softmax\"]\n",
    "\n",
    "\n",
    "histories = [0, 0, 0, 0, 0, 0]\n",
    "scores = []\n",
    "\n",
    "for i in range(6):\n",
    "    model = Sequential([\n",
    "        keras.layers.Flatten(input_shape = (28,28)),\n",
    "        keras.layers.Dense(first_layer_nodes[i], first_layer_activation[i]),\n",
    "        keras.layers.Dense(second_layer_nodes[i], second_layer_activation[i])\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer = 'adam',\n",
    "        loss = 'sparse_categorical_crossentropy',\n",
    "        metrics = ['accuracy']\n",
    "    )\n",
    "    histories[i] = model.fit(X_train_divided, y_train, epochs = 5, verbose = 1)\n",
    "    scores.append(model.evaluate(X_test_divided, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The history and score saving here is just to prove that it can be done. Here are some comparisons between the models that can be done very simply with no additional libraries. It's not the most comfortable way to judge the evolution of the models through their epochs of training, which is why we look to visualisation tools and libraries for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the metrics for the first model: \n",
      " {'loss': [0.2749541699886322, 0.12474231421947479, 0.08731238543987274, 0.06635019183158875, 0.051940008997917175], 'accuracy': [0.9214500188827515, 0.9631166458129883, 0.973800003528595, 0.9797000288963318, 0.9842000007629395]}\n",
      "\n",
      "This is the accuracy of the third model for each epoch: \n",
      " [0.10076666623353958, 0.09875000268220901, 0.09876666963100433, 0.09870000183582306, 0.09871666878461838]\n",
      "\n",
      "This is the loss of the 4th model after its 4th epoch: \n",
      " 3.166613817214966\n",
      "\n",
      "This is the accuracy evaluation of the 5th model: \n",
      " 0.9692999720573425\n",
      "\n",
      "The best model is model number 1 with an accuracy of 0.9733999967575073 %\n",
      "\n",
      "The worst model is model number 3 with an accuracy of 0.09799999743700027 %\n"
     ]
    }
   ],
   "source": [
    "print(\"These are the metrics for the first model: \\n\", histories[0].history)\n",
    "print(\"\\nThis is the accuracy of the third model for each epoch: \\n\", histories[2].history['accuracy'])\n",
    "print(\"\\nThis is the loss of the 4th model after its 4th epoch: \\n\", histories[3].history['loss'][3])\n",
    "print(\"\\nThis is the accuracy evaluation of the 5th model: \\n\", scores[4][1])\n",
    "\n",
    "max_accuracy = 0\n",
    "best_model = None\n",
    "for i in range(5):\n",
    "   if scores[i][1] > max_accuracy:\n",
    "      best_model = i\n",
    "      max_accuracy = scores[i][1]\n",
    "print(\"\\nThe best model is model number\", best_model +1, \"with an accuracy of\", max_accuracy, \"%\")\n",
    "\n",
    "min_accuracy = 100\n",
    "worst_model = None\n",
    "for i in range(5):\n",
    "   if scores[i][1] < min_accuracy:\n",
    "      worst_model = i\n",
    "      min_accuracy = scores[i][1]\n",
    "print(\"\\nThe worst model is model number\", worst_model +1, \"with an accuracy of\", min_accuracy, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
