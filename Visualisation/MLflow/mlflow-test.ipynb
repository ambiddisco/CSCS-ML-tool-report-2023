{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow test notebook\n",
    "This notebook contains the code used for testing MLflow with visualisation of the same MNIST models as the other tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirements:\n",
    "\n",
    "%pip install tensorflow mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist     \n",
    "from keras.models import Sequential  \n",
    "from keras.layers.core import Dense, Dropout, Activation \n",
    "from keras.utils import np_utils \n",
    "\n",
    "import mlflow\n",
    "from mlflow import log_metric, log_params, log_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the MNIST classifier dataset into training and testing sets\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# All values are between 0 and 255, dividing them to have values from 0 to 1:\n",
    "X_train_divided = X_train / 255\n",
    "X_test_divided = X_test / 255\n",
    "\n",
    "# Setting a few lists of variables to make varying the model output easy. \n",
    "first_layer_nodes = [100, 50, 100, 50, 100, 50]\n",
    "first_layer_activation = [\"relu\", \"sigmoid\", \"softmax\", \"relu\", \"sigmoid\", \"softmax\"]\n",
    "second_layer_nodes = [10, 15, 25, 25, 15, 10]\n",
    "second_layer_activation = [\"sigmoid\", \"softmax\", \"relu\", \"relu\", \"sigmoid\", \"softmax\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLflow serves the visualisations on a localhost, so fist of all that needs to be specified, followed by the creation of the experiment (you cannot use the same name twice) and the runs. Since MLflow is built based on TensorFlow, logging for keras models is available automatically, so in this case the automatic logging is used. Also, it should be noted that this time I forgot to name the runs and I'm not going to go change the graphs I already put in the report, so you have the occasion to see the default naming system, what an honour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up client and localhost\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "# Creating and naming experiment...\n",
    "experiment_name = \"MLflow MNIST test\"\n",
    "experiment_id = mlflow.create_experiment(experiment_name)\n",
    "\n",
    "for i in range(6):\n",
    "    with mlflow.start_run(experiment_id = experiment_id) as run:\n",
    "        log_params({ # Logging hyperparameters\n",
    "            \"architecture\": \"CNN\",\n",
    "            \"dataset\":  \"keras MNIST dataset\",\n",
    "            \"first layer nodes\": first_layer_nodes[i],\n",
    "            \"first layer activation\": first_layer_activation[i],\n",
    "            \"second layer nodes\": second_layer_nodes[i],\n",
    "            \"second layer activation\": second_layer_activation[i],\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"loss calculation\": \"sparse_categorical_crossentropy\",\n",
    "            \"epochs\": 5,\n",
    "        })\n",
    "        # Autologging, yay!\n",
    "        mlflow.tensorflow.autolog()\n",
    "\n",
    "        # Model creation, compilation and training.\n",
    "        model = Sequential([\n",
    "            keras.layers.Flatten(input_shape = (28,28)),\n",
    "            keras.layers.Dense(first_layer_nodes[i], first_layer_activation[i]),\n",
    "            keras.layers.Dense(second_layer_nodes[i], second_layer_activation[i])\n",
    "        ])\n",
    "        model.compile(\n",
    "            optimizer = 'adam',\n",
    "            loss = 'sparse_categorical_crossentropy',\n",
    "            metrics = ['accuracy']\n",
    "        )\n",
    "        history = model.fit(X_train_divided, y_train, epochs = 5, verbose = 1)\n",
    "        score = model.evaluate(X_test_divided, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the metrics are being served to a localhost connection, the visualisation graphs will only work so long as the connection is open, and once the localhost connection is no longer needed, it should be closed as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, one of the features of MLflow is uploading to the model registry through code instead of the client, so below we will create a model worth uploading, based on the knowledge gained from the visualisation of the 6 model variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed for the upload of model to the registry\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# Model creation, compilation and training, based on the best performing out of the 6 visualised so far\n",
    "model = Sequential([\n",
    "    keras.layers.Flatten(input_shape = (28,28)),\n",
    "    keras.layers.Dense(100, 'relu'),\n",
    "    keras.layers.Dense(10, 'sigmoid')\n",
    "])\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "history = model.fit(X_train_divided, y_train, epochs = 5, verbose = 1)\n",
    "score = model.evaluate(X_test_divided, y_test)\n",
    "\n",
    "# Model upload\n",
    "signature = infer_signature(X_test_divided, model.predict(X_test_divided))\n",
    "mlflow.tensorflow.log_model(model, \"MNIST_best_model\", signature=signature)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
