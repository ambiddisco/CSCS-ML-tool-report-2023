{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow test notebook\n",
    "This notebook contains the code used for testing MLflow with visualisation of the same MNIST models as the other tests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirements:\n",
    "\n",
    "%pip install tensorflow mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist     \n",
    "from keras.models import Sequential  \n",
    "from keras.layers import Dense, Dropout, Activation \n",
    "from keras.utils import np_utils \n",
    "\n",
    "import mlflow\n",
    "from mlflow import log_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the MNIST classifier dataset into training and testing sets\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# All values are between 0 and 255, dividing them to have values from 0 to 1:\n",
    "X_train_divided = X_train / 255\n",
    "X_test_divided = X_test / 255\n",
    "\n",
    "# Setting a few lists of variables to make varying the model output easy. \n",
    "first_layer_nodes = [100, 50, 100, 50, 100, 50]\n",
    "first_layer_activation = [\"relu\", \"sigmoid\", \"softmax\", \"relu\", \"sigmoid\", \"softmax\"]\n",
    "second_layer_nodes = [10, 15, 25, 25, 15, 10]\n",
    "second_layer_activation = [\"sigmoid\", \"softmax\", \"relu\", \"relu\", \"sigmoid\", \"softmax\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLflow serves the visualisations on a localhost. To start the visualisation server run the command \"mlflow server\" in a terminal. This can't be done in the notebook because by adding a cell with \"!mlflow server\", it will just keep running that one cell and never move on to subsequent cells, like the ones with logging code. \\\n",
    "Once the server has started, the localhost URL needs to be specified in the code, which will default to \"http://localhost:5000\", followed by the creation of the experiment (you cannot use the same name twice) and the runs. \\\n",
    "Since MLflow is built based on TensorFlow, logging for keras models is available automatically, so in this case the automatic logging is used. \\\n",
    "For manual logging the code should look like this:\n",
    "\n",
    " mlflow.log_params({  \\\n",
    "        \"epochs\": 10, \\\n",
    "        \"first-layer-dense\": 'relu', \\\n",
    "        \"second-layer-dense\": 'sigmoid' \\\n",
    "    }) \\\n",
    "    mlflow.log_metrics({ \\\n",
    "        \"accuracy\": score['accuracy'], \\\n",
    "        \"loss\": score['loss'] \\\n",
    "    }) \n",
    "\n",
    "\n",
    "You may notice that in the screenshots on the report I forgot to change the name of the runs, but that can be defined when creating the runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up client and localhost\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "# Creating and naming experiment...\n",
    "experiment_name = \"MLflow MNIST test\"\n",
    "experiment_id = mlflow.create_experiment(experiment_name)\n",
    "\n",
    "for i in range(6):\n",
    "    with mlflow.start_run(experiment_id = experiment_id, run_name = \"run-{}\".format(i+1)) as run:\n",
    "        log_params({ # Logging hyperparameters\n",
    "            \"architecture\": \"CNN\",\n",
    "            \"dataset\":  \"keras MNIST dataset\",\n",
    "            \"first layer nodes\": first_layer_nodes[i],\n",
    "            \"first layer activation\": first_layer_activation[i],\n",
    "            \"second layer nodes\": second_layer_nodes[i],\n",
    "            \"second layer activation\": second_layer_activation[i],\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"loss calculation\": \"sparse_categorical_crossentropy\",\n",
    "            \"epochs\": 5,\n",
    "        })\n",
    "        # Autologging, yay!\n",
    "        mlflow.tensorflow.autolog()\n",
    "\n",
    "        # Model creation, compilation and training.\n",
    "        model = Sequential([\n",
    "            keras.layers.Flatten(input_shape = (28,28)),\n",
    "            keras.layers.Dense(first_layer_nodes[i], first_layer_activation[i]),\n",
    "            keras.layers.Dense(second_layer_nodes[i], second_layer_activation[i])\n",
    "        ])\n",
    "        model.compile(\n",
    "            optimizer = 'adam',\n",
    "            loss = 'sparse_categorical_crossentropy',\n",
    "            metrics = ['accuracy']\n",
    "        )\n",
    "        model.fit(X_train_divided, y_train, epochs = 5, verbose = 1)\n",
    "        model.evaluate(X_test_divided, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you open a run manually (here I'm not counting it as manually because \"with mlflow.start_run(...)\" is used), you will also need to close the run, by using the functions \"mlflow.start_run(...)\" and then \"mlflow.end_run()\"\n",
    "\n",
    "Lastly, one of the features of MLflow is uploading to the model registry through code instead of the client, so below we will create a model worth uploading, based on the knowledge gained from the visualisation of the 6 model variations. If you do not specify an experiment and run, this will be uploaded in the default experiment section, as a model with logged metric. To upload to the model registry, locate the model you uploaded and click on the \"register\" button, then select the model name (passed through the \"registered_model_name\" variable when logging the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed for the upload of model to the registry\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# Model creation, compilation and training, based on the best performing out of the 6 visualised so far\n",
    "model_best = Sequential([\n",
    "    keras.layers.Flatten(input_shape = (28,28)),\n",
    "    keras.layers.Dense(100, 'relu'),\n",
    "    keras.layers.Dense(10, 'sigmoid')\n",
    "])\n",
    "model_best.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "model_best.fit(X_train_divided, y_train, epochs = 5, verbose = 1)\n",
    "model_best.evaluate(X_test_divided, y_test)\n",
    "\n",
    "# Model upload\n",
    "signature = infer_signature(X_test_divided, model.predict(X_test_divided))\n",
    "mlflow.tensorflow.log_model(model_best, \"MNIST_model\", registered_model_name = \"best_model\", signature=signature)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
